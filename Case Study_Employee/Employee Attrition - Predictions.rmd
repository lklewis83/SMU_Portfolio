---
title: "Employee Attrition"
author: "Lani Lewis"
date: "2023-04-01"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r  include = FALSE}
library(ggplot2)
library(tidyverse)
library(dplyr)
#install.packages("plotly")
library(plotly)
library(RCurl)
library(aws.s3)
library(gridExtra)
library(class)
#install.packages("class")
library(caret)
#install.packages("caret")
library(e1071)
library(kknn)
library(tinytex)
library(yardstick)
#install.packages("yardstick")
#library(pdflatex)
```

```{r}
# CSV IMPORT DATA ####
attrition <- read.csv("C:/Users/LA026LE/OneDrive - Pitney Bowes/MASTER DEGREE/GIT/Unit 14 and 15 Case Study 2/CaseStudy2-data.csv", header = T)
income <- read.csv("C:/Users/LA026LE/OneDrive - Pitney Bowes/MASTER DEGREE/GIT/Unit 14 and 15 Case Study 2/CaseStudy2CompSetNoIncome1.csv", header = T)
no_att <- read.csv("C:/Users/LA026LE/OneDrive - Pitney Bowes/MASTER DEGREE/GIT/Unit 14 and 15 Case Study 2/CaseStudy2CompSetNoAttrition.csv", header = T)
```

```{r}
# AWS IMPORT OF DATA ####
# Get your personal key from IAM "security credentials"
# Validate who your are accessing aws bucket
Sys.setenv("AWS_ACCESS_KEY_ID" = "AKIAQEJ7KGHWUUXL4UJV", 
           "AWS_SECRET_ACCESS_KEY" = "z/YE/OyZdY90FwSgjRUcWJ4sz+/6aZLOCA8vP9ya",
           "AWS_DEFAULT_REGION" = "us-east-2")


attrition_aws <- s3read_using(FUN = read.csv,                          
                          bucket = "ddsproject1", 
                          object = "CaseStudy2-data.csv") 


str(attrition_aws)
```



```{r}
# CLEAN DATA ####
## REPLACE attrition with new values ####
attrition$Attrition <- gsub("No", "Stayed", attrition$Attrition)
attrition$Attrition <- gsub("Yes", "Left", attrition$Attrition)
#attrition$Attrition

## FORCE COLORS FOR Attrition ####
colors <- c("Stayed" = "green", "Left" = "red")
```

INTRO
------

This document will be used to review the predictions of KNN, and Naive Bayes. And then perform a six step test.



```{r}
# CLEAN DATA ####
## Create Factor Variables for Classification ####
income$Attrition = as.factor(income$Attrition)

attrition$Attrition = as.factor(attrition$Attrition)
# attrition$Department = as.factor(attrition$Department)

# Regulate results
set.seed(123)

## Split Data 70-30 | Attrition ####
index <- createDataPartition(attrition$Attrition, p = 0.7, list = FALSE)

train_att <- attrition[index, ]

test_att <- attrition[-index, ]

## Split Data 70-30 | Monthly Income ####
index1 <- createDataPartition(attrition$MonthlyIncome, p = 0.7, list = FALSE)

train_income <- attrition[index1, ]

test_income <- attrition[-index1, ]
```

KNN - K Nearest Neighbors
----------------------

Find the Best K Option
```{r}
## Create a tuning grid ####
#tuneGrid <- expand.grid(kmax = 1:10, distance = 1:3, kernel = c("triangular", "epanechnikov", "gaussian"))
tuneGrid <- expand.grid(kmax = 1:10, distance = 1:3, kernel = c("gaussian"))

model <- train(MonthlyIncome ~ JobRole + Attrition, 
#model <- train(MonthlyIncome ~ Attrition, 
               method = "kknn", 
               data = train_att, 
               preProcess = c("center", "scale"), 
               tuneGrid = tuneGrid,
               trControl = trainControl(method = "cv", number = 10, verboseIter = TRUE))

# Determine the best K to use for KNN ####
# 10-fold cross-validation to choose the value of K
# minimizes the mean squared error (MSE)
best_k <- model$bestTune$kmax
```

KNN classification for attrition
```{r}
# KNN Test One ####
model3 <- knn(train_att[ , c("MonthlyIncome", "Age")], 
    test_att[ , c("MonthlyIncome", "Age")], 
    train_att$Attrition, 
    k = best_k, prob = T)
```

Validate KNN Model classifying for attrition
```{r}
confusionMatrix(model3, test_att$Attrition)

```

Cross Validation | Leave One Out Test
```{r}
# Leave One Out KNN ####
model4 <- knn.cv(attrition[ , c("MonthlyIncome", "Age")],
       attrition$Attrition,
       k = best_k)

confusionMatrix(attrition$Attrition, model4) # works
```

Increase the threshold option. 
Which only gives me a certain limit with the results off KNN Confusion Matrix
Sensitvity and Specificity


With attrition left being the postive class for validation
Accuracy will be sacrificed for Sensitivity and Specificity match
```{r}
# Threshold KNN ####

# Get probs from the model
probs = ifelse(model3 == "Left",attributes(model3)$prob, 1- attributes(model3)$prob)

# New Probability class where the threesold of left will be changed based on the prob value
# From the main dataset 140 left and 730 stayed
# 140 / 730 = .19178
NewModel = ifelse(probs > .19178, "Left", "Stayed")

# Validate the new model
CM = confusionMatrix(table(NewModel,test_att$Attrition))

CM
```

Oversampling KNN
I actually tested this first with Naive Bayes and had good results.
```{r}
# Oversampling #### 

## Original Value | 36 objects "columns"
left = train_att %>% filter(Attrition == "Left")
#dim(left)

# Add more "Left" Values | 36 objects "columns" | Oversample
leftOver = rbind(left,left[sample(seq(1,50,1),(356-50),replace = TRUE),])
#dim(leftOver)

# Add the over sample of fraud back to the full dataset
OverSamp1 = rbind(train_att %>% filter(Attrition == "Stayed"), leftOver)
#dim(OverSamp) # use this value

# Check the Oversampling split
sp_left = OverSamp1 %>% filter(Attrition == "Left")
#dim(sp_left)

sp_stay = OverSamp1 %>% filter(Attrition == "Stayed")
#dim(sp_stay)

summary(OverSamp1$Attrition)
```

KNN Oversampling classification for attrition
```{r}
# KNN Test One ####
model_ov <- knn(OverSamp1[ , c("MonthlyIncome", "Age")], 
    test_att[ , c("MonthlyIncome", "Age")], 
    OverSamp1$Attrition, 
    k = best_k, prob = T)


confusionMatrix(model_ov, test_att$Attrition)

```




Naive Bayes Review
--------------------

Naive Bayes Attrition Model
```{r}
nb_mod = naiveBayes(train_att[,c("MonthlyIncome","Age")],
                   train_att$Attrition, 
                   labels = c("Left", "Stayed"))

# -------------------------------------------

# nbmod = naiveBayes(Attrition~., data = train_att) 
# THis way cause a bunch of warning messages to appear when you validate with confussion Matrix
```

Naive Bayes Validation of Attrition Model
```{r}
nb_CM = confusionMatrix(table(factor(test_att$Attrition, 
                                  labels = c("Left", "Stayed")),
                           predict(nb_mod, test_att[,c("MonthlyIncome","Age")])))

nb_CM
```

```{r}
summary(train_att$Attrition)
# left 99 | Stayed 510
# 243 | 366
```

Oversampling Data
```{r}
# Oversampling Naive Bayes #### 

## Original Value | 36 objects "columns"
left = train_att %>% filter(Attrition == "Left")
#dim(left)

# Add more "Left" Values | 36 objects "columns" | Oversample
leftOver = rbind(left,left[sample(seq(1,98,1),(200-98),replace = TRUE),])
#dim(leftOver)

# Add the over sample of fraud back to the full dataset
OverSamp = rbind(train_att %>% filter(Attrition == "Stayed"), leftOver)
#dim(OverSamp) # use this value

# Check the Oversampling split
sp_left = OverSamp %>% filter(Attrition == "Left")
#dim(sp_left)

sp_stay = OverSamp %>% filter(Attrition == "Stayed")
#dim(sp_stay)

summary(OverSamp$Attrition)
```

```{r}
summary(train_att$Attrition) # Original Value

summary(OverSamp$Attrition) # Oversample Value
```

Oversampling Naive Bayes Attrition Model
```{r}
nb_mod1 = naiveBayes(OverSamp[,c("MonthlyIncome","Age")],
                   OverSamp$Attrition, 
                   labels = c("Left", "Stayed"))

# -------------------------------------------

nb_CM1 = confusionMatrix(table(factor(test_att$Attrition, 
                                  labels = c("Left", "Stayed")),
                           predict(nb_mod1, test_att[,c("MonthlyIncome","Age")])))

nb_CM1
```



```{r}
## Find average accuracy etc. of 100 train / test splits
AccHolder = numeric(100)
SensHolder = numeric(100)
SpecHolder = numeric(100)

for (seed in 1:100)
{
    set.seed(seed)
      ## Split Data 70-30 | Attrition ####
    index <- sample(seq(1:length(attrition$Attrition)),round(.7*length(attrition$Attrition)))
    
    train_att <- attrition[index, ]
    
    test_att <- attrition[-index, ]
    
    nb_mod <- naiveBayes(OverSamp[,c("MonthlyIncome","Age")],
                       OverSamp$Attrition, 
                       labels = c("Left", "Stayed"))
    
    CM <- confusionMatrix(table(factor(test_att$Attrition, 
                                      labels = c("Left", "Stayed")),
                               predict(nb_mod1, test_att[,c("MonthlyIncome","Age")])))
    
    AccHolder[seed] = CM$overall[1]
    SensHolder[seed] = CM$byClass[1]
    SpecHolder[seed] = CM$byClass[2]
}

mean(AccHolder)

#Standard Error of the Mean
sd(AccHolder)/sqrt(100) 

mean(SensHolder)

#Standard Error of the Mean
sd(SensHolder)/sqrt(100) 

mean(SpecHolder)

#Standard Error of the Mean
sd(SensHolder)/sqrt(100)
```

Six Step Test 
--------------

```{r}
# T TEST ####
#t.test(model3, predicted_values3, paired = TRUE)
# Error in complete.cases(x, y) : not all arguments have the same length
```