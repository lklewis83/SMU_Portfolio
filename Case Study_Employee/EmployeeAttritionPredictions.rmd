---
title: "Employee Attrition Predictions"
author: "Lani Lewis"
date: "2023-04-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r  include = FALSE}
library(ggplot2)
library(tidyverse)
library(dplyr)
#install.packages("plotly")
library(plotly)
library(RCurl)
library(aws.s3)
library(gridExtra)
library(class)
#install.packages("class")
library(caret)
#install.packages("caret")
library(e1071)
library(kknn)
library(tinytex)
library(yardstick)
#install.packages("yardstick")
#library(pdflatex)
#install.packages("formattable")
library(formattable)
```

```{r}
# CSV IMPORT DATA ####
attrition <- read.csv("CaseStudy2-data.csv", header = T)
```


AWS Data Bucket Pull and Test
------------------

Data will not always be available so this file will not run off the AWS datasets
```{r echo = FALSE}
# AWS IMPORT OF DATA ####
# Get your personal key from IAM "security credentials"
# Validate who your are accessing aws bucket
# Sys.setenv("AWS_ACCESS_KEY_ID" = "AKIAQEJ7KGHWUUXL4UJV", 
         #  "AWS_SECRET_ACCESS_KEY" = "z/YE/OyZdY90FwSgjRUcWJ4sz+/6aZLOCA8vP9ya",
          # "AWS_DEFAULT_REGION" = "us-east-2")
```

```{r}
#attrition_aws <- s3read_using(FUN = read.csv,                          
                         # bucket = "ddsproject1", 
                        #  object = "CaseStudy2-data.csv") 


#str(attrition_aws)
```

```{r}
# CLEAN DATA ####
## REPLACE attrition with new values ####
attrition$Attrition <- gsub("No", "Stayed", attrition$Attrition)
attrition$Attrition <- gsub("Yes", "Left", attrition$Attrition)
#attrition$Attrition

## FORCE COLORS FOR Attrition ####
colors <- c("Stayed" = "green", "Left" = "red")
```

INTRO
------

This document will be used to review the predictions of KNN, and Naive Bayes. And then perform a six step test.




Create Train and Test Sets
-------------------------

Create data sets for Monthly Income and Attrition for all models and predictions. I am performing a 70/30 split. 
```{r}
# CLEAN DATA ####

## Create Factor Variables for Classification ####
attrition$Attrition = as.factor(attrition$Attrition)


# Regulate results
set.seed(123)

## Split Data 70-30 | Attrition ####
index <- createDataPartition(attrition$Attrition, p = 0.7, list = FALSE)

train_att <- attrition[index, ]

test_att <- attrition[-index, ]

# --------------------------------------------

## Split Data 70-30 | Monthly Income ####
index1 <- createDataPartition(attrition$MonthlyIncome, p = 0.7, list = FALSE)

train_income <- attrition[index1, ]

test_income <- attrition[-index1, ]

# --------------------------------------------

# Convert Attrition and Department columns to character type
train_income$Attrition <- as.character(train_income$Attrition)
train_income$Department <- as.character(train_income$Department)

test_income$Attrition <- as.character(test_income$Attrition)
test_income$Department <- as.character(test_income$Department)

```

CLASSIFICATION MODELS
---------------------


KNN - K Nearest Neighbors
----------------------

I will be using the KNN model for attrition classification (probability) only. I will use other models for Monthly Income classificaiton (Probability).


Find the Best K Option
```{r echo = FALSE}
## Create a tuning grid ####
tuneGrid <- expand.grid(kmax = 1:10, distance = 1:3, kernel = c("gaussian"))

# Attrition BestK
modela <- train(Attrition ~ JobRole + Department, 
               method = "kknn", 
               data = train_att, 
               preProcess = c("center", "scale"), 
               tuneGrid = tuneGrid,
               trControl = trainControl(method = "cv", number = 10, verboseIter = TRUE))
```

```{r}
# Determine the best K to use for KNN ####
# 10-fold cross-validation to choose the value of K
# minimizes the mean squared error (MSE)
bestk <- modela$bestTune$kmax # Attrition

bestk
```

KNN classification for Base Line attrition
```{r}
# KNN model3 | Attrition ####
model3 <- knn(train_att[ , c("MonthlyIncome", "Age")], 
    test_att[ , c("MonthlyIncome", "Age")], 
    train_att$Attrition, 
    k = bestk, prob = T)

```

Validate KNN Model classifying for attrition
```{r}
confusionMatrix(model3, test_att$Attrition)

```


- KNN Cross Validation | Leave One Out Test

in this case I am not using a train and test model. Instead I am classifying (finding probability) against the entire dataset using specific classifiers.
```{r}
# Leave One Out KNN ####
model4 <- knn.cv(attrition[ , c("MonthlyIncome", "Age")],
       attrition$Attrition,
       k = bestk)

confusionMatrix(attrition$Attrition, model4) 
```

Increase the threshold option. 
Which only gives me a certain limit with the results off KNN Confusion Matrix
Sensitvity and Specificity


```{r}
summary(train_att$Attrition)
```


With attrition "left" probability being the postive classifier for validation. Accuracy will be sacrificed for Sensitivity and Specificity match

- Fitting the KNN Models for Specific Results


Changing the threeshold of the "left" variable, So that I will have more "left" options in my training set when I create my model.
```{r}
# Threshold KNN ####

# Get probs from the model
probs = ifelse(model3 == "Left",attributes(model3)$prob, 1- attributes(model3)$prob)

# New Probability class where the threesold of left will be changed based on the prob value
# From the main dataset 140 left and 730 stayed
# 140 / 730 = .19178
NewModel = ifelse(probs > .19178, "Left", "Stayed")

# Validate the new model
CM = confusionMatrix(table(NewModel,test_att$Attrition))

CM
```

- Oversampling KNN

I actually tested this first with Naive Bayes and had good results. Similiar to before I will have more "left" options in my training set when I create my model.
```{r}
# Oversampling #### 
set.seed(123)
## Original Value | 36 objects "columns"
left = train_att %>% filter(Attrition == "Left")
#dim(left)

# Add more "Left" Values | 36 objects "columns" | Oversample
leftOver = rbind(left,left[sample(seq(1,85,1),(560-85),replace = TRUE),])
#dim(leftOver)

# Add the over sample of fraud back to the full dataset
OverSamp1 = rbind(train_att %>% filter(Attrition == "Stayed"), leftOver)
#dim(OverSamp) # use this value

# Check the Oversampling split
sp_left = OverSamp1 %>% filter(Attrition == "Left")
#dim(sp_left)

sp_stay = OverSamp1 %>% filter(Attrition == "Stayed")
#dim(sp_stay)

summary(OverSamp1$Attrition)
```

KNN Oversampling classification for attrition
```{r}
# KNN Test One ####
model_ov <- knn(OverSamp1[ , c("MonthlyIncome", "Age")], 
    test_att[ , c("MonthlyIncome", "Age")], 
    OverSamp1$Attrition, 
    k = bestk, prob = T)


confusionMatrix(model_ov, test_att$Attrition)

```

Naive Bayes Review
--------------------

- Naive Bayes Model Creation
```{r}
# NB Attrition Models ####
# attrition with classifiers
nb_mod = naiveBayes(train_att[,c("MonthlyIncome","Age")],
                   train_att$Attrition)

# -------------------------------------------
# NB Monthly Income Models ####
# Monthly Income with classifiers
nbmod = naiveBayes(train_income[,c("Attrition","Age")],
                   train_income$MonthlyIncome)
```



- Naive Bayes predictions for Attrition
```{r}
nb_pred <- predict(nb_mod,  test_att[,c("MonthlyIncome","Age")], type = 'raw')

write.csv(nb_pred, "Case2Predictionslani Attrition.csv")
```

- Naive Bayes Classification or probabilities for Attrition Model

This is the base line for Naive Bayes
```{r}
nb_CM = confusionMatrix(table(predict(nb_mod,  test_att[,c("MonthlyIncome","Age")]),  test_att$Attrition))

nb_CM
```


Oversampling Data NB Attrition
```{r}
# Oversampling Naive Bayes | Attrition #### 

## Original Value | 36 objects "columns"
left = train_att %>% filter(Attrition == "Left")
#dim(left)

# Add more "Left" Values | 36 objects "columns" | Oversample
leftOver = rbind(left,left[sample(seq(1,98,1),(406-98),replace = TRUE),])
#dim(leftOver)

# Add the over sample of fraud back to the full dataset
OverSamp = rbind(train_att %>% filter(Attrition == "Stayed"), leftOver)
#dim(OverSamp) # use this value

# Check the Oversampling split
sp_left = OverSamp %>% filter(Attrition == "Left")
#dim(sp_left)

sp_stay = OverSamp %>% filter(Attrition == "Stayed")
#dim(sp_stay)

summary(OverSamp$Attrition)
```

Oversampling Naive Bayes Attrition Model
```{r}
nb_mod1 = naiveBayes(OverSamp[,c("MonthlyIncome","Age")],
                   OverSamp$Attrition)

# -------------------------------------------

nb_CM1 = confusionMatrix(table(predict(nb_mod1,  test_att[,c("MonthlyIncome","Age")]),  test_att$Attrition))

nb_CM1
```

- Naive Bayes predictions for Monthly Income Model

I can not run the confussion matrix against a binomial numeric value. I can make predictions.

```{r}
## NB Oversampling predictions for Attrition ####
ov_nb_pred <- predict(nb_mod1,  test_att[,c("MonthlyIncome","Age")])

write.csv(ov_nb_pred, "Case2OVSampPredictlani Attrition.csv")
```



```{r}
## NB Prediction for Monthly Income ####
pred <- predict(nbmod,  data.frame(JobRole = "Manager", Age = 37), type = 'raw')

write.csv(pred, "Case2Predictionslani Salary.csv")
```


Predict Missing Values via the MEAN and MODE
-----------------

Monthly Income Predict Missing Values using mean prediction
```{r}
# Obtain the Mean MonthlyIncome and save to a dataset
mean_income <- aggregate(MonthlyIncome ~ Attrition + JobRole + Age, data = attrition, FUN = base::mean)


# Save the mean monthly income values to a CSV file
write.csv(mean_income, "MeanIncome.csv")
```

Attrition Predict for Missing values using mode prediction
```{r}
# Define a custom function to calculate the mode
mode_function <- function(x) 
  {
  table_x <- table(x)
  mode_x <- names(table_x)[which.max(table_x)]
  return(mode_x)
  }


# Obtain the Mode Attrition and save to a dataset
mode_Attrition <- aggregate(Attrition ~ Department + JobRole + Age, data = attrition, FUN = mode_function)


# Save the mean monthly income values to a CSV file
write.csv(mode_Attrition, "ModeAttrition.csv")
```




Linear Regression Classification
--------------

Obtain an RMSE which is less than 3000. When assumptions for SLR are met our best estimate of the standard deviation will be the RMSE. The smaller the RMSE the better the model has classified
```{r}
fit <- lm(MonthlyIncome ~ JobRole, data = train_income)

current_rse <- summary(fit)$sigma

summary(fit)
```


Linear Regression Prediction
--------------

predictions are made based off the x value from the fit model
```{r}
## SLR Monthly Income Prediction ####
fit_pred <- predict(fit)

write.csv(fit_pred, "Case2SLRPredictlani Salary.csv")
```

estimate what the Monthly Income would be for a Sales Executive at the Age of 19
```{r}
df_est <- data.frame(JobRole = "Sales Executive", Age = 19)
# when I used sales representative I got an error...
# factor JobRole has new level Sales Reresentative

predicted_income <- predict(fit, newdata = df_est)

# write.csv(mode_Attrition, "ModeAttrition.csv")

# Format the predicted income as a money (currency) variable with a dollar sign
currency(predicted_income, symbol = "$")

```


